{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\nimport psutil\nimport csv\nimport os\nimport torchvision.models as models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:27:08.123479Z","iopub.execute_input":"2025-05-13T01:27:08.124012Z","iopub.status.idle":"2025-05-13T01:27:15.019182Z","shell.execute_reply.started":"2025-05-13T01:27:08.123989Z","shell.execute_reply":"2025-05-13T01:27:15.018629Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# -------- Device Setup --------\nif not torch.cuda.is_available():\n    raise RuntimeError(\"CUDA is not available.\")\ndevice = torch.device(\"cuda\")\nprint(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n\n# -------- Dataset Setup --------\ntransform = transforms.Compose([\n    transforms.Resize(224),  # ResNet expects 224x224\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntestset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\ntestloader  = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n\n# -------- Model Setup --------\nmodel = models.resnet18(pretrained=False)\nmodel.fc = nn.Linear(model.fc.in_features, 10)  # For CIFAR-10\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:27:15.020164Z","iopub.execute_input":"2025-05-13T01:27:15.020494Z","iopub.status.idle":"2025-05-13T01:27:21.014171Z","shell.execute_reply.started":"2025-05-13T01:27:15.020466Z","shell.execute_reply":"2025-05-13T01:27:21.013401Z"}},"outputs":[{"name":"stdout","text":"Using GPU: Tesla T4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 75.7MB/s] \n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -------- CSV Logging Setup --------\ncsv_file = 'resnet18_pytorch_cuda.csv'\nwith open(csv_file, mode='w', newline='') as f:\n    writer = csv.writer(f)\n    writer.writerow([\n        \"Epoch\", \"Image_Number\", \"Batch_Index\", \"Loss\",\n        \"RAM_Usage_MB\", \"GPU_Alloc_MB\", \"Time_Per_Batch_s\",\n        \"Train_Accuracy(%)\", \"Test_Accuracy(%)\"\n    ])\n\n# -------- Training Loop --------\nnum_epochs = 10\nmodel.train()\n\nfor epoch in range(num_epochs):\n    correct_train, total_train = 0, 0\n\n    for batch_idx, (images, labels) in enumerate(trainloader):\n        start = time.perf_counter()\n\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Accuracy tracking\n        _, predicted = torch.max(outputs.data, 1)\n        correct_train += (predicted == labels).sum().item()\n        total_train += labels.size(0)\n\n        end = time.perf_counter()\n\n        # System metrics\n        ram = psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024)\n        gpu_mem = torch.cuda.memory_allocated() / (1024 ** 2)\n        elapsed = end - start\n        image_number = batch_idx * images.size(0)\n\n        # Log batch\n        with open(csv_file, mode='a', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow([\n                epoch + 1, image_number, batch_idx, f\"{loss.item():.4f}\",\n                f\"{ram:.2f}\", f\"{gpu_mem:.2f}\", f\"{elapsed:.6f}\", \"\", \"\"\n            ])\n\n        if batch_idx % 100 == 0:\n            print(f\"[Epoch {epoch+1}] Image {image_number}, Batch {batch_idx}: \"\n                  f\"Loss={loss.item():.4f}, RAM={ram:.2f}MB, GPU={gpu_mem:.2f}MB, Time={elapsed:.6f}s\")\n\n    # -------- Epoch Accuracy Logging --------\n    train_accuracy = 100 * correct_train / total_train\n\n    model.eval()\n    correct_test, total_test = 0, 0\n    with torch.no_grad():\n        for images, labels in testloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            correct_test += (predicted == labels).sum().item()\n            total_test += labels.size(0)\n    test_accuracy = 100 * correct_test / total_test\n\n    print(f\"[Epoch {epoch+1}] Train Accuracy: {train_accuracy:.2f}% | Test Accuracy: {test_accuracy:.2f}%\")\n    model.train()\n\n    # Log epoch summary\n    with open(csv_file, mode='a', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            epoch + 1, \"END\", \"-\", \"-\", \"-\", \"-\", \"-\",\n            f\"{train_accuracy:.2f}\", f\"{test_accuracy:.2f}\"\n        ])\n\nprint(f\"Final GPU Memory Used: {torch.cuda.memory_allocated() / (1024 ** 2):.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T01:27:21.014942Z","iopub.execute_input":"2025-05-13T01:27:21.015638Z","iopub.status.idle":"2025-05-13T01:58:28.909142Z","shell.execute_reply.started":"2025-05-13T01:27:21.015592Z","shell.execute_reply":"2025-05-13T01:58:28.908313Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1] Image 0, Batch 0: Loss=2.3525, RAM=1403.35MB, GPU=228.06MB, Time=1.248730s\n[Epoch 1] Image 6400, Batch 100: Loss=1.6906, RAM=1404.37MB, GPU=225.68MB, Time=0.177925s\n[Epoch 1] Image 12800, Batch 200: Loss=1.4454, RAM=1404.37MB, GPU=225.68MB, Time=0.182656s\n[Epoch 1] Image 19200, Batch 300: Loss=1.3552, RAM=1404.44MB, GPU=225.68MB, Time=0.188235s\n[Epoch 1] Image 25600, Batch 400: Loss=1.1507, RAM=1404.45MB, GPU=225.68MB, Time=0.195215s\n[Epoch 1] Image 32000, Batch 500: Loss=1.2024, RAM=1404.62MB, GPU=225.68MB, Time=0.201311s\n[Epoch 1] Image 38400, Batch 600: Loss=1.2549, RAM=1404.55MB, GPU=225.68MB, Time=0.217868s\n[Epoch 1] Image 44800, Batch 700: Loss=1.0348, RAM=1404.51MB, GPU=225.68MB, Time=0.211615s\n[Epoch 1] Train Accuracy: 51.79% | Test Accuracy: 59.72%\n[Epoch 2] Image 0, Batch 0: Loss=1.0603, RAM=1433.47MB, GPU=225.56MB, Time=0.209345s\n[Epoch 2] Image 6400, Batch 100: Loss=0.6612, RAM=1433.61MB, GPU=225.93MB, Time=0.214878s\n[Epoch 2] Image 12800, Batch 200: Loss=0.9153, RAM=1433.55MB, GPU=225.93MB, Time=0.209594s\n[Epoch 2] Image 19200, Batch 300: Loss=0.9613, RAM=1433.51MB, GPU=225.93MB, Time=0.209562s\n[Epoch 2] Image 25600, Batch 400: Loss=0.8056, RAM=1433.55MB, GPU=225.93MB, Time=0.209172s\n[Epoch 2] Image 32000, Batch 500: Loss=0.8029, RAM=1433.62MB, GPU=225.93MB, Time=0.211258s\n[Epoch 2] Image 38400, Batch 600: Loss=0.6624, RAM=1433.62MB, GPU=225.93MB, Time=0.210641s\n[Epoch 2] Image 44800, Batch 700: Loss=0.8101, RAM=1433.62MB, GPU=225.93MB, Time=0.210252s\n[Epoch 2] Train Accuracy: 71.92% | Test Accuracy: 74.03%\n[Epoch 3] Image 0, Batch 0: Loss=0.4937, RAM=1433.77MB, GPU=225.87MB, Time=0.210772s\n[Epoch 3] Image 6400, Batch 100: Loss=0.5835, RAM=1433.61MB, GPU=225.68MB, Time=0.209065s\n[Epoch 3] Image 12800, Batch 200: Loss=0.5509, RAM=1433.86MB, GPU=225.68MB, Time=0.208419s\n[Epoch 3] Image 19200, Batch 300: Loss=0.5613, RAM=1433.87MB, GPU=225.68MB, Time=0.211691s\n[Epoch 3] Image 25600, Batch 400: Loss=0.7725, RAM=1433.76MB, GPU=225.68MB, Time=0.210611s\n[Epoch 3] Image 32000, Batch 500: Loss=0.3388, RAM=1433.86MB, GPU=225.68MB, Time=0.213215s\n[Epoch 3] Image 38400, Batch 600: Loss=0.6572, RAM=1433.81MB, GPU=225.68MB, Time=0.209704s\n[Epoch 3] Image 44800, Batch 700: Loss=0.4269, RAM=1433.86MB, GPU=225.68MB, Time=0.207131s\n[Epoch 3] Train Accuracy: 78.63% | Test Accuracy: 77.09%\n[Epoch 4] Image 0, Batch 0: Loss=0.5401, RAM=1433.66MB, GPU=225.81MB, Time=0.213745s\n[Epoch 4] Image 6400, Batch 100: Loss=0.4789, RAM=1433.87MB, GPU=225.68MB, Time=0.211562s\n[Epoch 4] Image 12800, Batch 200: Loss=0.2441, RAM=1433.75MB, GPU=225.68MB, Time=0.209795s\n[Epoch 4] Image 19200, Batch 300: Loss=0.7074, RAM=1433.87MB, GPU=225.68MB, Time=0.211825s\n[Epoch 4] Image 25600, Batch 400: Loss=0.5445, RAM=1433.86MB, GPU=225.68MB, Time=0.210628s\n[Epoch 4] Image 32000, Batch 500: Loss=0.5005, RAM=1433.87MB, GPU=225.68MB, Time=0.209071s\n[Epoch 4] Image 38400, Batch 600: Loss=0.6809, RAM=1433.87MB, GPU=225.68MB, Time=0.207766s\n[Epoch 4] Image 44800, Batch 700: Loss=0.6590, RAM=1433.79MB, GPU=225.68MB, Time=0.208719s\n[Epoch 4] Train Accuracy: 83.48% | Test Accuracy: 76.18%\n[Epoch 5] Image 0, Batch 0: Loss=0.2595, RAM=1433.89MB, GPU=225.56MB, Time=0.208923s\n[Epoch 5] Image 6400, Batch 100: Loss=0.3896, RAM=1433.87MB, GPU=225.93MB, Time=0.209756s\n[Epoch 5] Image 12800, Batch 200: Loss=0.6442, RAM=1433.76MB, GPU=225.93MB, Time=0.208093s\n[Epoch 5] Image 19200, Batch 300: Loss=0.2913, RAM=1433.80MB, GPU=225.93MB, Time=0.209007s\n[Epoch 5] Image 25600, Batch 400: Loss=0.4834, RAM=1433.87MB, GPU=225.93MB, Time=0.209728s\n[Epoch 5] Image 32000, Batch 500: Loss=0.3369, RAM=1433.68MB, GPU=225.93MB, Time=0.210521s\n[Epoch 5] Image 38400, Batch 600: Loss=0.3213, RAM=1433.87MB, GPU=225.93MB, Time=0.211324s\n[Epoch 5] Image 44800, Batch 700: Loss=0.3966, RAM=1433.87MB, GPU=225.93MB, Time=0.209482s\n[Epoch 5] Train Accuracy: 86.67% | Test Accuracy: 79.37%\n[Epoch 6] Image 0, Batch 0: Loss=0.2549, RAM=1433.89MB, GPU=225.87MB, Time=0.206610s\n[Epoch 6] Image 6400, Batch 100: Loss=0.2073, RAM=1433.95MB, GPU=225.68MB, Time=0.209991s\n[Epoch 6] Image 12800, Batch 200: Loss=0.3297, RAM=1433.95MB, GPU=225.68MB, Time=0.208655s\n[Epoch 6] Image 19200, Batch 300: Loss=0.2642, RAM=1433.99MB, GPU=225.68MB, Time=0.210951s\n[Epoch 6] Image 25600, Batch 400: Loss=0.3050, RAM=1433.99MB, GPU=225.68MB, Time=0.211030s\n[Epoch 6] Image 32000, Batch 500: Loss=0.3723, RAM=1433.99MB, GPU=225.68MB, Time=0.210204s\n[Epoch 6] Image 38400, Batch 600: Loss=0.3681, RAM=1433.95MB, GPU=225.68MB, Time=0.210093s\n[Epoch 6] Image 44800, Batch 700: Loss=0.1954, RAM=1433.99MB, GPU=225.68MB, Time=0.210134s\n[Epoch 6] Train Accuracy: 89.50% | Test Accuracy: 82.93%\n[Epoch 7] Image 0, Batch 0: Loss=0.2431, RAM=1434.08MB, GPU=225.81MB, Time=0.214161s\n[Epoch 7] Image 6400, Batch 100: Loss=0.1870, RAM=1434.05MB, GPU=225.68MB, Time=0.210559s\n[Epoch 7] Image 12800, Batch 200: Loss=0.2377, RAM=1434.05MB, GPU=225.68MB, Time=0.211812s\n[Epoch 7] Image 19200, Batch 300: Loss=0.2138, RAM=1434.01MB, GPU=225.68MB, Time=0.212855s\n[Epoch 7] Image 25600, Batch 400: Loss=0.1649, RAM=1434.02MB, GPU=225.68MB, Time=0.210094s\n[Epoch 7] Image 32000, Batch 500: Loss=0.3648, RAM=1434.12MB, GPU=225.68MB, Time=0.209785s\n[Epoch 7] Image 38400, Batch 600: Loss=0.2125, RAM=1434.12MB, GPU=225.68MB, Time=0.206819s\n[Epoch 7] Image 44800, Batch 700: Loss=0.2499, RAM=1434.07MB, GPU=225.68MB, Time=0.208315s\n[Epoch 7] Train Accuracy: 92.13% | Test Accuracy: 83.25%\n[Epoch 8] Image 0, Batch 0: Loss=0.0718, RAM=1434.03MB, GPU=225.56MB, Time=0.206377s\n[Epoch 8] Image 6400, Batch 100: Loss=0.1409, RAM=1434.07MB, GPU=225.93MB, Time=0.207336s\n[Epoch 8] Image 12800, Batch 200: Loss=0.2835, RAM=1434.05MB, GPU=225.93MB, Time=0.208816s\n[Epoch 8] Image 19200, Batch 300: Loss=0.0727, RAM=1434.05MB, GPU=225.93MB, Time=0.208008s\n[Epoch 8] Image 25600, Batch 400: Loss=0.2399, RAM=1434.05MB, GPU=225.93MB, Time=0.209312s\n[Epoch 8] Image 32000, Batch 500: Loss=0.2352, RAM=1434.12MB, GPU=225.93MB, Time=0.210512s\n[Epoch 8] Image 38400, Batch 600: Loss=0.1329, RAM=1434.12MB, GPU=225.93MB, Time=0.209730s\n[Epoch 8] Image 44800, Batch 700: Loss=0.0973, RAM=1434.12MB, GPU=225.93MB, Time=0.211159s\n[Epoch 8] Train Accuracy: 94.20% | Test Accuracy: 81.27%\n[Epoch 9] Image 0, Batch 0: Loss=0.1408, RAM=1434.02MB, GPU=225.87MB, Time=0.212948s\n[Epoch 9] Image 6400, Batch 100: Loss=0.1465, RAM=1434.12MB, GPU=225.68MB, Time=0.209875s\n[Epoch 9] Image 12800, Batch 200: Loss=0.0850, RAM=1434.11MB, GPU=225.68MB, Time=0.209293s\n[Epoch 9] Image 19200, Batch 300: Loss=0.0825, RAM=1434.12MB, GPU=225.68MB, Time=0.210685s\n[Epoch 9] Image 25600, Batch 400: Loss=0.1666, RAM=1434.12MB, GPU=225.68MB, Time=0.211389s\n[Epoch 9] Image 32000, Batch 500: Loss=0.2313, RAM=1434.11MB, GPU=225.68MB, Time=0.209222s\n[Epoch 9] Image 38400, Batch 600: Loss=0.1179, RAM=1434.05MB, GPU=225.68MB, Time=0.208781s\n[Epoch 9] Image 44800, Batch 700: Loss=0.2441, RAM=1434.05MB, GPU=225.68MB, Time=0.209392s\n[Epoch 9] Train Accuracy: 95.92% | Test Accuracy: 83.35%\n[Epoch 10] Image 0, Batch 0: Loss=0.1286, RAM=1433.91MB, GPU=225.81MB, Time=0.211002s\n[Epoch 10] Image 6400, Batch 100: Loss=0.1089, RAM=1433.82MB, GPU=225.68MB, Time=0.208439s\n[Epoch 10] Image 12800, Batch 200: Loss=0.1202, RAM=1434.00MB, GPU=225.68MB, Time=0.207666s\n[Epoch 10] Image 19200, Batch 300: Loss=0.0449, RAM=1433.96MB, GPU=225.68MB, Time=0.209997s\n[Epoch 10] Image 25600, Batch 400: Loss=0.1131, RAM=1434.05MB, GPU=225.68MB, Time=0.212446s\n[Epoch 10] Image 32000, Batch 500: Loss=0.1027, RAM=1434.12MB, GPU=225.68MB, Time=0.205429s\n[Epoch 10] Image 38400, Batch 600: Loss=0.1333, RAM=1434.12MB, GPU=225.68MB, Time=0.209369s\n[Epoch 10] Image 44800, Batch 700: Loss=0.0761, RAM=1434.12MB, GPU=225.68MB, Time=0.208097s\n[Epoch 10] Train Accuracy: 96.77% | Test Accuracy: 81.11%\nFinal GPU Memory Used: 199.06 MB\n","output_type":"stream"}],"execution_count":3}]}